{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Lambda, Merge, Embedding\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 1, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 2\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 16\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 1)\n",
    "# convolution kernel size\n",
    "kernel_size = (5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "(x + y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "from theano import function\n",
    "from theano import pp\n",
    "x = T.dscalar('x')\n",
    "y = T.dscalar('y')\n",
    "z = x + y\n",
    "f = function([x, y], z)\n",
    "print(f(2, 3))\n",
    "print(pp(z))\n",
    "z.eval({x : 2, y : 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n",
      "[[[[518 871 797 274 325]\n",
      "   [827 766 832 931 368]\n",
      "   [562 381 507 506   3]\n",
      "   [842 136 938 854 190]]\n",
      "\n",
      "  [[923 394 122 315 320]\n",
      "   [109 307 488 424 744]\n",
      "   [321 997 668 311 620]\n",
      "   [792  79 228 657 101]]\n",
      "\n",
      "  [[598 918 168 495 734]\n",
      "   [596 207  78  50 966]\n",
      "   [161 822 937 572 244]\n",
      "   [102 607 387 324 397]]]\n",
      "\n",
      "\n",
      " [[[592 504 438 655 858]\n",
      "   [476 526 421 514 365]\n",
      "   [652 172 664 847 673]\n",
      "   [ 71 829  23 517 393]]\n",
      "\n",
      "  [[771 743 408 879 351]\n",
      "   [224 739 193 547 732]\n",
      "   [995 907 258 519 235]\n",
      "   [403 886 542  29 116]]\n",
      "\n",
      "  [[919 759 704 431 694]\n",
      "   [868 450 959 823 563]\n",
      "   [804 612 509 803 541]\n",
      "   [270 725 129 216 301]]]]\n",
      "4\n",
      "[[[ 842.  871.  938.  931.  368.]\n",
      "  [ 923.  997.  668.  657.  744.]\n",
      "  [ 598.  918.  937.  572.  966.]]\n",
      "\n",
      " [[ 652.  829.  664.  847.  858.]\n",
      "  [ 995.  907.  542.  879.  732.]\n",
      "  [ 919.  759.  959.  823.  694.]]]\n",
      "[[[[0 3 2 0 2]\n",
      "   [2 2 0 2 3]\n",
      "   [1 1 1 3 0]\n",
      "   [3 0 3 1 1]]\n",
      "\n",
      "  [[1 3 0 2 3]\n",
      "   [2 1 3 0 0]\n",
      "   [3 0 1 1 2]\n",
      "   [0 2 2 3 1]]\n",
      "\n",
      "  [[3 1 1 1 2]\n",
      "   [2 3 0 3 3]\n",
      "   [1 2 3 0 0]\n",
      "   [0 0 2 2 1]]]\n",
      "\n",
      "\n",
      " [[[3 2 3 1 1]\n",
      "   [1 0 1 3 3]\n",
      "   [0 1 0 0 2]\n",
      "   [2 3 2 2 0]]\n",
      "\n",
      "  [[1 1 1 3 3]\n",
      "   [3 0 2 2 2]\n",
      "   [0 3 0 1 0]\n",
      "   [2 2 3 0 1]]\n",
      "\n",
      "  [[3 1 3 3 3]\n",
      "   [2 2 2 0 2]\n",
      "   [1 3 0 2 1]\n",
      "   [0 0 1 1 0]]]]\n",
      "[[[[1 0 1 1 0]\n",
      "   [3 1 3 3 1]]\n",
      "\n",
      "  [[0 0 1 1 1]\n",
      "   [3 2 2 3 2]]\n",
      "\n",
      "  [[0 0 2 0 0]\n",
      "   [1 2 3 2 1]]]\n",
      "\n",
      "\n",
      " [[[0 1 0 0 0]\n",
      "   [2 3 2 2 2]]\n",
      "\n",
      "  [[0 2 0 0 0]\n",
      "   [2 3 3 1 1]]\n",
      "\n",
      "  [[0 0 0 1 0]\n",
      "   [1 3 1 2 1]]]]\n",
      "[0 0 1 1 2 2 3 3 4 4]\n",
      "[[0 0 1 1 2]\n",
      " [2 3 3 4 4]]\n",
      "[[0 0 1 1 2 2 3 3 4 4]]\n"
     ]
    }
   ],
   "source": [
    "###important indexing method!!\n",
    "b=np.random.rand(3, 3)\n",
    "i = [(1,0),(0,1),(2,1)]\n",
    "i=np.asarray(i)\n",
    "b[i[:,0],i[:,1]]\n",
    "\n",
    "np.random.seed(12)\n",
    "a = np.random.choice(1000, 120, replace=False)\n",
    "a = a.reshape((2,3,4,5))\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "x = T.dtensor4('x')\n",
    "\n",
    "shape = x.shape[2]\n",
    "getshape=function([x],shape)\n",
    "print(getshape(a))\n",
    "\n",
    "args1 = T.max(x, axis=2)\n",
    "maxvalue = function([x],args1)\n",
    "print(maxvalue(a))\n",
    "\n",
    "args = T.argsort(x, axis=2)\n",
    "print(function([x],args)(a))\n",
    "\n",
    "k=2\n",
    "args = T.argsort(x, axis=2)\n",
    "kargs = args[:,:,-k:,:]\n",
    "kargs = T.sort(kargs, axis=2)\n",
    "# z = kargs.shape\n",
    "maxf = function([x],kargs)\n",
    "print(maxf(a))\n",
    "\n",
    "\n",
    "mymax = T.iscalar('mymax')\n",
    "rep = T.iscalar('rep')\n",
    "myrange = T.arange(mymax).repeat(rep)\n",
    "getindex = function([mymax,rep], myrange)\n",
    "print(getindex(5,2))\n",
    "##output [0 0 1 1 2 2 3 3 4 4]\n",
    "\n",
    "mymax = T.iscalar('mymax')\n",
    "rep = T.iscalar('rep')\n",
    "res1 = T.iscalar('res1')\n",
    "res2 = T.iscalar('res2')\n",
    "myrange = T.arange(mymax).repeat(rep).reshape((res1,res2))\n",
    "getindex2 = function([mymax,rep,res1,res2], myrange)\n",
    "print(getindex2(5,2,2,5))\n",
    "##output [[0 0 1 1 2]\n",
    "# [2 3 3 4 4]]\n",
    "print(getindex2(5,2,1,-1)) \n",
    "## output [[0 0 1 1 2 2 3 3 4 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5)\n",
      "[[[[518 871 797 274 325]\n",
      "   [827 766 832 931 368]\n",
      "   [562 381 507 506   3]\n",
      "   [842 136 938 854 190]]\n",
      "\n",
      "  [[923 394 122 315 320]\n",
      "   [109 307 488 424 744]\n",
      "   [321 997 668 311 620]\n",
      "   [792  79 228 657 101]]\n",
      "\n",
      "  [[598 918 168 495 734]\n",
      "   [596 207  78  50 966]\n",
      "   [161 822 937 572 244]\n",
      "   [102 607 387 324 397]]]\n",
      "\n",
      "\n",
      " [[[592 504 438 655 858]\n",
      "   [476 526 421 514 365]\n",
      "   [652 172 664 847 673]\n",
      "   [ 71 829  23 517 393]]\n",
      "\n",
      "  [[771 743 408 879 351]\n",
      "   [224 739 193 547 732]\n",
      "   [995 907 258 519 235]\n",
      "   [403 886 542  29 116]]\n",
      "\n",
      "  [[919 759 704 431 694]\n",
      "   [868 450 959 823 563]\n",
      "   [804 612 509 803 541]\n",
      "   [270 725 129 216 301]]]]\n",
      "[[[[827 871 832 931 325]\n",
      "   [842 766 938 854 368]]\n",
      "\n",
      "  [[923 394 488 424 744]\n",
      "   [792 997 668 657 620]]\n",
      "\n",
      "  [[598 918 937 495 734]\n",
      "   [596 822 387 572 966]]]\n",
      "\n",
      "\n",
      " [[[592 526 438 655 858]\n",
      "   [652 829 664 847 673]]\n",
      "\n",
      "  [[771 907 408 879 351]\n",
      "   [995 886 542 547 732]]\n",
      "\n",
      "  [[919 759 704 823 694]\n",
      "   [868 725 959 803 563]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "a = np.random.choice(1000, 120, replace=False)\n",
    "a = a.reshape((2,3,4,5))\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "####axis = 3\n",
    "# asort = np.argsort(a,axis=3)\n",
    "# ksort = np.sort(asort[:,:,:,-k:],axis=3)\n",
    "\n",
    "# dim0 = np.asarray(range(2)).repeat(3*4*2)\n",
    "# dim1 = np.asarray(range(3)).repeat(4*2).reshape((1,-1)).repeat(2,axis=0).flatten()\n",
    "# dim2 = np.asarray(range(4)).repeat(2).reshape((1,-1)).repeat(2*3,axis=0).flatten()\n",
    "# dim3 = ksort.flatten()\n",
    "\n",
    "#### axis = 2\n",
    "asort = np.argsort(a,axis=2)\n",
    "ksort = np.sort(asort[:,:,-k:,:],axis=2)\n",
    "\n",
    "dim0 = np.asarray(range(2)).repeat(3*2*5)\n",
    "dim1 = np.asarray(range(3)).repeat(2*5).reshape((1,-1)).repeat(2,axis=0).flatten()\n",
    "dim2 = ksort.flatten()\n",
    "dim3 = np.asarray(range(5)).reshape((1,-1)).repeat(2*3*2,axis=0).flatten()\n",
    "\n",
    "print(a[dim0,dim1,dim2,dim3].reshape((2,3,2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), array([1, 0, 1, 1, 0, 3, 1, 3, 3, 1, 0, 0, 1, 1, 1, 3, 2, 2, 3, 2, 0, 0, 2,\n",
      "       0, 0, 1, 2, 3, 2, 1, 0, 1, 0, 0, 0, 2, 3, 2, 2, 2, 0, 2, 0, 0, 0, 2,\n",
      "       3, 3, 1, 1, 0, 0, 0, 1, 0, 1, 3, 1, 2, 1]), array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2,\n",
      "       3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,\n",
      "       1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4])]\n",
      "[ 518.  871.  797.  274.  325.  827.  766.  832.  931.  368.  562.  381.\n",
      "  507.  506.    3.  842.  136.  938.  854.  190.  923.  394.  122.  315.\n",
      "  320.  109.  307.  488.  424.  744.  321.  997.  668.  311.  620.  792.\n",
      "   79.  228.  657.  101.  598.  918.  168.  495.  734.  596.  207.   78.\n",
      "   50.  966.  161.  822.  937.  572.  244.  102.  607.  387.  324.  397.\n",
      "  592.  504.  438.  655.  858.  476.  526.  421.  514.  365.  652.  172.\n",
      "  664.  847.  673.   71.  829.   23.  517.  393.  771.  743.  408.  879.\n",
      "  351.  224.  739.  193.  547.  732.  995.  907.  258.  519.  235.  403.\n",
      "  886.  542.   29.  116.  919.  759.  704.  431.  694.  868.  450.  959.\n",
      "  823.  563.  804.  612.  509.  803.  541.  270.  725.  129.  216.  301.]\n",
      "[ 5  1  7  8  4 15  6 17 18  9 10 11 17 18 19 25 21 22 28 24 20 21 32 23 24\n",
      " 25 31 37 33 29 30 36 32 33 34 40 46 42 43 44 40 51 42 43 44 50 56 57 48 49\n",
      " 50 51 52 58 54 55 66 57 63 59]\n",
      "[[[[ 827.  871.  832.  931.  325.]\n",
      "   [ 842.  766.  938.  854.  368.]]\n",
      "\n",
      "  [[ 562.  381.  938.  854.  190.]\n",
      "   [ 109.  394.  122.  424.  320.]]\n",
      "\n",
      "  [[ 923.  394.  668.  315.  320.]\n",
      "   [ 109.  997.  228.  311.  744.]]]\n",
      "\n",
      "\n",
      " [[[ 321.   79.  668.  311.  620.]\n",
      "   [ 598.  207.  168.  495.  734.]]\n",
      "\n",
      "  [[ 598.  822.  168.  495.  734.]\n",
      "   [ 161.  607.  387.   50.  966.]]\n",
      "\n",
      "  [[ 161.  822.  937.  324.  244.]\n",
      "   [ 102.  526.  387.  655.  397.]]]]\n",
      "[[[[518 871 797 274 325]\n",
      "   [827 766 832 931 368]\n",
      "   [562 381 507 506   3]\n",
      "   [842 136 938 854 190]]\n",
      "\n",
      "  [[923 394 122 315 320]\n",
      "   [109 307 488 424 744]\n",
      "   [321 997 668 311 620]\n",
      "   [792  79 228 657 101]]\n",
      "\n",
      "  [[598 918 168 495 734]\n",
      "   [596 207  78  50 966]\n",
      "   [161 822 937 572 244]\n",
      "   [102 607 387 324 397]]]\n",
      "\n",
      "\n",
      " [[[592 504 438 655 858]\n",
      "   [476 526 421 514 365]\n",
      "   [652 172 664 847 673]\n",
      "   [ 71 829  23 517 393]]\n",
      "\n",
      "  [[771 743 408 879 351]\n",
      "   [224 739 193 547 732]\n",
      "   [995 907 258 519 235]\n",
      "   [403 886 542  29 116]]\n",
      "\n",
      "  [[919 759 704 431 694]\n",
      "   [868 450 959 823 563]\n",
      "   [804 612 509 803 541]\n",
      "   [270 725 129 216 301]]]]\n",
      "[[[[ 827.  871.  832.  931.  325.]\n",
      "   [ 842.  766.  938.  854.  368.]]\n",
      "\n",
      "  [[ 562.  381.  938.  854.  190.]\n",
      "   [ 109.  394.  122.  424.  320.]]\n",
      "\n",
      "  [[ 923.  394.  668.  315.  320.]\n",
      "   [ 109.  997.  228.  311.  744.]]]\n",
      "\n",
      "\n",
      " [[[ 321.   79.  668.  311.  620.]\n",
      "   [ 598.  207.  168.  495.  734.]]\n",
      "\n",
      "  [[ 598.  822.  168.  495.  734.]\n",
      "   [ 161.  607.  387.   50.  966.]]\n",
      "\n",
      "  [[ 161.  822.  937.  324.  244.]\n",
      "   [ 102.  526.  387.  655.  397.]]]]\n"
     ]
    }
   ],
   "source": [
    "x = T.dtensor4('x')\n",
    "k=2\n",
    "sorted_values = T.argsort(x,axis=2)\n",
    "topmax_indexes = sorted_values[:,:,-k:,:]\n",
    "topmax_indexes_sorted = T.sort(topmax_indexes,axis=2)    \n",
    "dim0 = T.arange(0,x.shape[0]).repeat(x.shape[1]*k*x.shape[3])\n",
    "dim1 = T.arange(0,x.shape[1]).repeat(k*x.shape[3]).reshape((1,-1)).repeat(x.shape[0],axis=0).flatten()\n",
    "dim2 = topmax_indexes_sorted.flatten()\n",
    "dim3 = T.arange(0,x.shape[3]).reshape((1,-1)).repeat(x.shape[0]*x.shape[1]*k,axis=0).flatten()\n",
    "res=x[dim0,dim1,dim2,dim3].reshape((x.shape[0], x.shape[1], k, x.shape[3]))\n",
    "\n",
    "f = theano.function([x],[dim0,dim1,dim2,dim3])\n",
    "print(f(a))\n",
    "xx=x.flatten()\n",
    "f1 = theano.function([x],xx)\n",
    "f2 = theano.function([x],dim3+dim0*3*2*5+dim1*2*5+dim2*5)\n",
    "f3 = theano.function([x],xx[dim3+dim0*3*2*5+dim1*2*5+dim2*5].reshape((2,3,2,5)))\n",
    "print(f1(a))\n",
    "print(f2(a))\n",
    "print(f3(a))\n",
    "print(a)\n",
    "theano.printing.debugprint(f3(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:7: DeprecationWarning: Division of two integer types with x / y is deprecated, please use x // y for an integer division.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "12928/60000 [=====>........................] - ETA: 19s - loss: 1.4669 - acc: 0.4982"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-da017081d0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n\u001b[0;32m---> 67\u001b[0;31m           verbose=1, validation_data=(X_test, Y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def themax(x):\n",
    "    return T.max(x, axis=2)\n",
    "\n",
    "###axis = 2\n",
    "def k_max(x):\n",
    "#     k=T.iscalar('k')\n",
    "    k = x.shape[2]/2\n",
    "    sorted_values = T.argsort(x,axis=2)\n",
    "    topmax_indexes = sorted_values[:,:,-k:,:]\n",
    "    # sort indexes so that we keep the correct order within the sentence\n",
    "    topmax_indexes_sorted = T.sort(topmax_indexes,axis=2)    \n",
    "    #given that topmax only gives the index of the third dimension, we need to generate the other 3 dimensions\n",
    "    dim0 = T.arange(0,x.shape[0]).repeat(x.shape[1]*k*x.shape[3])\n",
    "    dim1 = T.arange(0,x.shape[1]).repeat(k*x.shape[3]).reshape((1,-1)).repeat(x.shape[0],axis=0).flatten()\n",
    "    dim2 = topmax_indexes_sorted.flatten()\n",
    "    dim3 = T.arange(0,x.shape[3]).reshape((1,-1)).repeat(x.shape[0]*x.shape[1]*k,axis=0).flatten()\n",
    "    return x[dim0,dim1,dim2,dim3].reshape((x.shape[0], x.shape[1], k, x.shape[3]))\n",
    "\n",
    "##aixs = 3\n",
    "def k_max2(x):\n",
    "#     k=T.iscalar('k')\n",
    "#     k=x.shape[3]/2\n",
    "    k=5\n",
    "    sorted_values = T.argsort(x,axis=3)\n",
    "    topmax_indexes = sorted_values[:,:,:,-k:]\n",
    "    # sort indexes so that we keep the correct order within the sentence\n",
    "    topmax_indexes_sorted = T.sort(topmax_indexes)    \n",
    "    #given that topmax only gives the index of the third dimension, we need to generate the other 3 dimensions\n",
    "    dim0 = T.arange(0,x.shape[0]).repeat(x.shape[1]*x.shape[2]*k)\n",
    "    dim1 = T.arange(0,x.shape[1]).repeat(k*x.shape[2]).reshape((1,-1)).repeat(x.shape[0],axis=0).flatten()\n",
    "    dim2 = T.arange(0,x.shape[2]).repeat(k).reshape((1,-1)).repeat(x.shape[0]*x.shape[1],axis=0).flatten()\n",
    "    dim3 = topmax_indexes_sorted.flatten()\n",
    "    return x[dim0,dim1,dim2,dim3].reshape((x.shape[0], x.shape[1], x.shape[2],k))\n",
    "\n",
    "def output_shape_f(shape):\n",
    "    return (shape[0],shape[1],shape[2]/2,shape[3])    \n",
    "\n",
    "def output_shape_f2(shape):\n",
    "    return (shape[0],shape[1],shape[2],5)  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "kmax_layer = Lambda(function=k_max, output_shape=output_shape_f)\n",
    "model.add(kmax_layer)\n",
    "# model.add(AveragePooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 19s - loss: 0.5924 - acc: 0.8063 - val_loss: 0.1169 - val_acc: 0.9638\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 18s - loss: 0.2141 - acc: 0.9367 - val_loss: 0.0880 - val_acc: 0.9718\n",
      "Test score: 0.0879899788989\n",
      "Test accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_activations(model, layer, X_batch):\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output])\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dropout at 0x7f5e78123290>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape\n",
    "model.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Convolution2D object at 0x7f5e781b9a90>\n",
      "<keras.layers.core.Activation object at 0x7f5e781316d0>\n",
      "convolution2d_input_2\n",
      "TensorType(float32, 4D)\n",
      "(3, 1, 28, 28)\n",
      "(3, 16, 8, 20)\n",
      "[ 0.01824202  0.          0.          0.          0.          0.07622255\n",
      "  0.26356173  0.22608617  0.17033559  0.26586303  0.44771817  0.59780973\n",
      "  1.21221602  1.80400455  2.54239893  2.69711947  2.54329491  2.21155906\n",
      "  1.71171498  1.17737687]\n",
      "[ 0.3264716   0.46496376  0.57620698  0.65903562  0.99940348  1.42767763\n",
      "  1.59193778  1.55196595  0.853104    0.63897258  0.30281779  0.09640662\n",
      "  0.          0.          0.          1.4456352   1.42369044  1.17533433\n",
      "  0.83574235  0.47179934]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test=X_train[:3]\n",
    "print(model.layers[0])\n",
    "print(model.layers[5])\n",
    "print(model.layers[0].input)\n",
    "print(model.layers[0].input.type)\n",
    "res=get_activations(model, 5, test)[0]\n",
    "print(test.shape)\n",
    "print(res.shape)\n",
    "print(res[0][0][2])\n",
    "res2=get_activations(model, 6, test)[0]\n",
    "print(res2[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_7 (Convolution2D)  (None, 16, 24, 24)    416         convolution2d_input_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 16, 24, 24)    0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 16, 20, 20)    6416        activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 16, 20, 20)    0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 16, 20, 20)    0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 6400)          0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           819328      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 128)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 128)           0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            1290        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 10)            0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 827450\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
