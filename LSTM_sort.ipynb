{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from __future__ import print_function\n",
    "from keras.layers.core import Activation, TimeDistributedDense, RepeatVector\n",
    "from keras.layers import recurrent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, vocab, maxlen):\n",
    "        self.vocab = vocab\n",
    "        self.maxlen = maxlen\n",
    "    \n",
    "    def encode(self, C, maxlen=None):\n",
    "        maxlen = maxlen if maxlen else self.maxlen\n",
    "        X = np.zeros((maxlen, len(self.vocab)))\n",
    "        for i, c in enumerate(C):\n",
    "            X[i, c] = 1\n",
    "        return X\n",
    "    \n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ','.join(x for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRandSeq(min, max, len):\n",
    "    return [np.random.randint(min, max) for _ in range(len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 10000\n",
    "TEST_SIZE = 10000\n",
    "DIGITS = 25\n",
    "MAXLEN = DIGITS\n",
    "voc = list(xrange(10))\n",
    "ctable = CharacterTable(voc, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "[6, 0, 5, 2, 2, 8, 5, 5, 8, 2, 6, 9, 0, 5, 1, 6, 6, 9, 1, 0, 8, 1, 5, 2, 9]\n",
      "[0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 5, 6, 6, 6, 6, 8, 8, 8, 9, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "inputs_t = []\n",
    "outputs_t = []\n",
    "print('Generating data...')\n",
    "while len(inputs) < TRAINING_SIZE:\n",
    "    s = generateRandSeq(0, len(voc), DIGITS)\n",
    "    inputs.append(s)\n",
    "    # outputs.append(s[::-1])\n",
    "    outputs.append(sorted(s))\n",
    "\n",
    "while len(inputs_t) < TEST_SIZE:\n",
    "    s = generateRandSeq(0, len(voc), DIGITS)\n",
    "    inputs_t.append(s)\n",
    "    # outputs_t.append(s[::-1])\n",
    "    outputs_t.append(sorted(s))\n",
    "print(inputs[12])\n",
    "print(outputs[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(inputs), MAXLEN, len(voc)), dtype=np.bool)\n",
    "y = np.zeros((len(outputs), MAXLEN, len(voc)), dtype=np.bool)\n",
    "for i, sentence in enumerate(inputs):\n",
    "    X[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "\n",
    "for i, sentence in enumerate(outputs):\n",
    "    y[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "\n",
    "X_test = np.zeros((len(inputs_t), MAXLEN, len(voc)), dtype=np.bool)\n",
    "y_test = np.zeros((len(outputs_t), MAXLEN, len(voc)), dtype=np.bool)\n",
    "for i, sentence in enumerate(inputs_t):\n",
    "    X_test[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "\n",
    "for i, sentence in enumerate(outputs_t):\n",
    "    y_test[i] = ctable.encode(sentence, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 25, 10)\n",
      "(10000, 25, 10)\n",
      "(10000, 25, 10)\n",
      "(10000, 25, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 200\n",
    "LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(MAXLEN, len(voc)), return_sequences=True))\n",
    "for _ in range(LAYERS - 2):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(HIDDEN_SIZE))\n",
    "model.add(RepeatVector(MAXLEN))\n",
    "for _ in range(LAYERS):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributedDense(len(voc)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1991 - acc: 0.9171 - val_loss: 0.2455 - val_acc: 0.8904\n",
      "Epoch 2/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.2066 - acc: 0.9108 - val_loss: 0.2400 - val_acc: 0.8975\n",
      "Epoch 3/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.2026 - acc: 0.9148 - val_loss: 0.4054 - val_acc: 0.8476\n",
      "Epoch 4/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1930 - acc: 0.9354 - val_loss: 0.0587 - val_acc: 0.9975\n",
      "Epoch 5/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1876 - acc: 0.9377 - val_loss: 0.5082 - val_acc: 0.8294\n",
      "Epoch 6/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1961 - acc: 0.9316 - val_loss: 0.0787 - val_acc: 0.9820\n",
      "Epoch 7/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1824 - acc: 0.9392 - val_loss: 0.2359 - val_acc: 0.9222\n",
      "Epoch 8/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.2091 - acc: 0.9288 - val_loss: 0.2265 - val_acc: 0.9073\n",
      "Epoch 9/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1791 - acc: 0.9464 - val_loss: 0.1689 - val_acc: 0.9325\n",
      "Epoch 10/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1756 - acc: 0.9421 - val_loss: 0.0791 - val_acc: 0.9826\n",
      "Epoch 11/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1740 - acc: 0.9454 - val_loss: 0.0458 - val_acc: 0.9982\n",
      "Epoch 12/161\n",
      "9000/9000 [==============================] - 19s - loss: 0.1753 - acc: 0.9454 - val_loss: 0.0706 - val_acc: 0.9848\n",
      "Epoch 13/161\n",
      "9000/9000 [==============================] - 19s - loss: 0.1666 - acc: 0.9464 - val_loss: 0.0766 - val_acc: 0.9807\n",
      "Epoch 14/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1521 - acc: 0.9495 - val_loss: 0.2193 - val_acc: 0.9211\n",
      "Epoch 15/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1964 - acc: 0.9394 - val_loss: 0.5161 - val_acc: 0.8194\n",
      "Epoch 16/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1536 - acc: 0.9524 - val_loss: 0.7309 - val_acc: 0.7611\n",
      "Epoch 17/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1995 - acc: 0.9295 - val_loss: 0.0849 - val_acc: 0.9746\n",
      "Epoch 18/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1528 - acc: 0.9477 - val_loss: 0.0385 - val_acc: 0.9986\n",
      "Epoch 19/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1791 - acc: 0.9479 - val_loss: 0.0594 - val_acc: 0.9920\n",
      "Epoch 20/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1597 - acc: 0.9487 - val_loss: 0.0823 - val_acc: 0.9797\n",
      "Epoch 21/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1533 - acc: 0.9594 - val_loss: 0.4025 - val_acc: 0.8495\n",
      "Epoch 22/161\n",
      "9000/9000 [==============================] - 20s - loss: 0.1616 - acc: 0.9499 - val_loss: 0.5248 - val_acc: 0.8040\n",
      "Epoch 23/161\n",
      "9000/9000 [==============================] - 20s - loss: 0.1526 - acc: 0.9487 - val_loss: 0.1889 - val_acc: 0.9185\n",
      "Epoch 24/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1334 - acc: 0.9586 - val_loss: 0.0277 - val_acc: 0.9988\n",
      "Epoch 25/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1846 - acc: 0.9506 - val_loss: 0.1540 - val_acc: 0.9385\n",
      "Epoch 26/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1183 - acc: 0.9667 - val_loss: 0.0262 - val_acc: 0.9986\n",
      "Epoch 27/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1513 - acc: 0.9499 - val_loss: 0.0265 - val_acc: 0.9990\n",
      "Epoch 28/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1319 - acc: 0.9678 - val_loss: 1.1475 - val_acc: 0.7336\n",
      "Epoch 29/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1735 - acc: 0.9507 - val_loss: 0.0266 - val_acc: 0.9985\n",
      "Epoch 30/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1101 - acc: 0.9712 - val_loss: 0.0210 - val_acc: 0.9990\n",
      "Epoch 31/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1852 - acc: 0.9497 - val_loss: 0.1233 - val_acc: 0.9468\n",
      "Epoch 32/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1038 - acc: 0.9726 - val_loss: 0.0212 - val_acc: 0.9990\n",
      "Epoch 33/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1321 - acc: 0.9639 - val_loss: 1.1000 - val_acc: 0.7319\n",
      "Epoch 34/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1851 - acc: 0.9496 - val_loss: 0.0588 - val_acc: 0.9834\n",
      "Epoch 35/161\n",
      "9000/9000 [==============================] - 18s - loss: 0.1079 - acc: 0.9748 - val_loss: 0.0199 - val_acc: 0.9988\n",
      "Epoch 36/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1184 - acc: 0.9714 - val_loss: 1.1151 - val_acc: 0.7315\n",
      "Epoch 37/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1868 - acc: 0.9482 - val_loss: 0.0283 - val_acc: 0.9978\n",
      "Epoch 38/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1144 - acc: 0.9717 - val_loss: 0.0200 - val_acc: 0.9989\n",
      "Epoch 39/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1161 - acc: 0.9707 - val_loss: 0.0178 - val_acc: 0.9990\n",
      "Epoch 40/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1120 - acc: 0.9723 - val_loss: 0.0177 - val_acc: 0.9988\n",
      "Epoch 41/161\n",
      "9000/9000 [==============================] - 23s - loss: 0.1823 - acc: 0.9552 - val_loss: 0.4161 - val_acc: 0.8588\n",
      "Epoch 42/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1324 - acc: 0.9657 - val_loss: 0.0208 - val_acc: 0.9988\n",
      "Epoch 43/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1196 - acc: 0.9693 - val_loss: 0.0184 - val_acc: 0.9988\n",
      "Epoch 44/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1182 - acc: 0.9682 - val_loss: 0.0179 - val_acc: 0.9989\n",
      "Epoch 45/161\n",
      "9000/9000 [==============================] - 18s - loss: 0.1169 - acc: 0.9697 - val_loss: 0.0168 - val_acc: 0.9988\n",
      "Epoch 46/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1163 - acc: 0.9685 - val_loss: 0.0157 - val_acc: 0.9990\n",
      "Epoch 47/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1219 - acc: 0.9706 - val_loss: 0.0143 - val_acc: 0.9991\n",
      "Epoch 48/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1185 - acc: 0.9686 - val_loss: 0.0188 - val_acc: 0.9980\n",
      "Epoch 49/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1701 - acc: 0.9609 - val_loss: 0.4206 - val_acc: 0.8690\n",
      "Epoch 50/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1393 - acc: 0.9651 - val_loss: 0.1003 - val_acc: 0.9634\n",
      "Epoch 51/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1197 - acc: 0.9710 - val_loss: 0.0171 - val_acc: 0.9986\n",
      "Epoch 52/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1250 - acc: 0.9656 - val_loss: 0.0277 - val_acc: 0.9937\n",
      "Epoch 53/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1058 - acc: 0.9751 - val_loss: 0.0156 - val_acc: 0.9989\n",
      "Epoch 54/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1225 - acc: 0.9687 - val_loss: 0.0157 - val_acc: 0.9988\n",
      "Epoch 55/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1062 - acc: 0.9763 - val_loss: 0.0141 - val_acc: 0.9988\n",
      "Epoch 56/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1181 - acc: 0.9736 - val_loss: 0.0135 - val_acc: 0.9989\n",
      "Epoch 57/161\n",
      "9000/9000 [==============================] - 20s - loss: 0.1228 - acc: 0.9719 - val_loss: 0.0137 - val_acc: 0.9991\n",
      "Epoch 58/161\n",
      "9000/9000 [==============================] - 19s - loss: 0.1161 - acc: 0.9707 - val_loss: 0.0140 - val_acc: 0.9990\n",
      "Epoch 59/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1133 - acc: 0.9741 - val_loss: 0.0132 - val_acc: 0.9989\n",
      "Epoch 60/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1017 - acc: 0.9765 - val_loss: 0.0123 - val_acc: 0.9991\n",
      "Epoch 61/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1122 - acc: 0.9751 - val_loss: 0.0120 - val_acc: 0.9991\n",
      "Epoch 62/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1140 - acc: 0.9729 - val_loss: 0.0123 - val_acc: 0.9990\n",
      "Epoch 63/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1082 - acc: 0.9737 - val_loss: 0.0116 - val_acc: 0.9991\n",
      "Epoch 64/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1053 - acc: 0.9770 - val_loss: 0.0110 - val_acc: 0.9991\n",
      "Epoch 65/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1222 - acc: 0.9696 - val_loss: 0.0109 - val_acc: 0.9992\n",
      "Epoch 66/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1227 - acc: 0.9689 - val_loss: 0.0106 - val_acc: 0.9992\n",
      "Epoch 67/161\n",
      "9000/9000 [==============================] - 19s - loss: 0.1129 - acc: 0.9725 - val_loss: 0.0113 - val_acc: 0.9992\n",
      "Epoch 68/161\n",
      "9000/9000 [==============================] - 19s - loss: 0.1142 - acc: 0.9727 - val_loss: 0.0110 - val_acc: 0.9991\n",
      "Epoch 69/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1163 - acc: 0.9755 - val_loss: 0.0115 - val_acc: 0.9988\n",
      "Epoch 70/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1106 - acc: 0.9745 - val_loss: 0.0111 - val_acc: 0.9990\n",
      "Epoch 71/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1058 - acc: 0.9749 - val_loss: 0.0108 - val_acc: 0.9992\n",
      "Epoch 72/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1276 - acc: 0.9704 - val_loss: 0.0111 - val_acc: 0.9991\n",
      "Epoch 73/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1210 - acc: 0.9727 - val_loss: 0.0112 - val_acc: 0.9991\n",
      "Epoch 74/161\n",
      "9000/9000 [==============================] - 22s - loss: 0.1112 - acc: 0.9720 - val_loss: 0.0131 - val_acc: 0.9989\n",
      "Epoch 75/161\n",
      "9000/9000 [==============================] - 21s - loss: 0.1115 - acc: 0.9744 - val_loss: 0.0223 - val_acc: 0.9952\n",
      "10000/10000 [==============================] - 9s     \n",
      "Test score: 0.0205255381577\n",
      "Test accuracy: 0.995580012798\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8)\n",
    "hist = model.fit(X, y, batch_size=BATCH_SIZE, nb_epoch=161, callbacks=[early_stopping],\n",
    "          validation_split = 0.1, shuffle=True)\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            show_accuracy=True)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, 7, 6, 5, 4, 3, 2, 1, 0, 0, 8, 7, 7, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '12345678901234567898'\n",
    "x_test = ctable.encode(test, maxlen=MAXLEN)\n",
    "X_test = np.zeros((1, MAXLEN, len(chars)), dtype=np.bool)\n",
    "X_test[0] = x_test\n",
    "res = model.predict_classes(X_test)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "axes = plt.gca()\n",
    "x_min = hist.epoch[0]\n",
    "x_max = hist.epoch[-1]+1\n",
    "axes.set_xlim([x_min,x_max])\n",
    "\n",
    "plt.scatter(hist.epoch, hist.history['loss'], color='g')\n",
    "plt.plot(hist.history['loss'], color='g', label='Training Loss')\n",
    "plt.scatter(hist.epoch, hist.history['val_loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='b', label='Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss & Validation Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "axes = plt.gca()\n",
    "x_min = hist.epoch[0]\n",
    "x_max = hist.epoch[-1]+1\n",
    "axes.set_xlim([x_min,x_max])\n",
    "\n",
    "plt.scatter(hist.epoch, hist.history['acc'], color='r')\n",
    "plt.plot(hist.history['acc'], color='r', label='Training Accuracy')\n",
    "plt.scatter(hist.epoch, hist.history['val_acc'], color='c')\n",
    "plt.plot(hist.history['val_acc'], color='c', label='Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Trainging Accuracy & Validation Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
