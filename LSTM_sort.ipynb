{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from __future__ import print_function\n",
    "from keras.layers.core import Activation, TimeDistributedDense, RepeatVector\n",
    "from keras.layers import recurrent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    '''\n",
    "    Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilties to their character output\n",
    "    '''\n",
    "    def __init__(self, chars, maxlen):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def encode(self, C, maxlen=None):\n",
    "        maxlen = maxlen if maxlen else self.maxlen\n",
    "        X = np.zeros((maxlen, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            X[i, self.char_indices[c]] = 1\n",
    "        return X\n",
    "\n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(digits):\n",
    "    return ''.join([str(np.random.randint(0, 9)) for _ in range(digits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 50000\n",
    "TEST_SIZE = 10000\n",
    "DIGITS = 50\n",
    "MAXLEN = DIGITS\n",
    "chars = '0123456789'\n",
    "ctable = CharacterTable(chars, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "43475457570151080538413805578265851041648730143840\n",
      "04834103784614015856287550831483508015107575457434\n",
      "12548177470071435851317678881702480772000564513724\n",
      "42731546500027708420718887671315853417007477184521\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "inputs_t = []\n",
    "outputs_t = []\n",
    "print('Generating data...')\n",
    "while len(inputs) < TRAINING_SIZE:\n",
    "    s = generate(DIGITS)\n",
    "    inputs.append(s)\n",
    "    outputs.append(s[::-1])\n",
    "    \n",
    "while len(inputs_t) < TEST_SIZE:\n",
    "    s = generate(DIGITS)\n",
    "    inputs_t.append(s)\n",
    "    outputs_t.append(s[::-1])\n",
    "print(inputs[12])\n",
    "print(outputs[12])\n",
    "print(inputs_t[12])\n",
    "print(outputs_t[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "[[False False False False  True False False False False False]\n",
      " [False False False  True False False False False False False]\n",
      " [False False False False  True False False False False False]\n",
      " [False False False False False False False  True False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False False  True False False False False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False False False False False  True False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False False False False False  True False False]\n",
      " [ True False False False False False False False False False]\n",
      " [False  True False False False False False False False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False  True False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [False False False False False False False False  True False]\n",
      " [ True False False False False False False False False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False  True False False False False False False]\n",
      " [False False False False False False False False  True False]\n",
      " [False False False False  True False False False False False]\n",
      " [False  True False False False False False False False False]\n",
      " [False False False  True False False False False False False]\n",
      " [False False False False False False False False  True False]\n",
      " [ True False False False False False False False False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False False False False False  True False False]\n",
      " [False False False False False False False False  True False]\n",
      " [False False  True False False False False False False False]\n",
      " [False False False False False False  True False False False]\n",
      " [False False False False False  True False False False False]\n",
      " [False False False False False False False False  True False]\n",
      " [False False False False False  True False False False False]\n",
      " [False  True False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [False False False False  True False False False False False]\n",
      " [False  True False False False False False False False False]\n",
      " [False False False False False False  True False False False]\n",
      " [False False False False  True False False False False False]\n",
      " [False False False False False False False False  True False]\n",
      " [False False False False False False False  True False False]\n",
      " [False False False  True False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [False  True False False False False False False False False]\n",
      " [False False False False  True False False False False False]\n",
      " [False False False  True False False False False False False]\n",
      " [False False False False False False False False  True False]\n",
      " [False False False False  True False False False False False]\n",
      " [ True False False False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(inputs), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(outputs), MAXLEN, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(inputs):\n",
    "    X[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "for i, sentence in enumerate(outputs):\n",
    "    y[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "    \n",
    "X_test = np.zeros((len(inputs_t), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y_test = np.zeros((len(outputs_t), MAXLEN, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(inputs_t):\n",
    "    X_test[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "for i, sentence in enumerate(outputs_t):\n",
    "    y_test[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "    \n",
    "print(X[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 50, 10)\n",
      "(50000, 50, 10)\n",
      "(10000, 50, 10)\n",
      "(10000, 50, 10)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 100\n",
    "LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# dropout_W=0.1, dropout_U=0.1,\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars)), return_sequences=True))\n",
    "for _ in range(LAYERS - 2):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "model.add(LSTM(HIDDEN_SIZE))\n",
    "model.add(RepeatVector(MAXLEN))\n",
    "for _ in range(LAYERS):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributedDense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "39500/45000 [=========================>....] - ETA: 15s - loss: 1.9837 - acc: 0.2402"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, batch_size=BATCH_SIZE, nb_epoch=5,\n",
    "          show_accuracy=True,validation_split = 0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s     \n",
      "Test score: 0.000568637109245\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            show_accuracy=True)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, 7, 6, 5, 4, 3, 2, 1, 0, 0, 8, 7, 7, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '12345678901234567898'\n",
    "x_test = ctable.encode(test, maxlen=MAXLEN)\n",
    "X_test = np.zeros((1, MAXLEN, len(chars)), dtype=np.bool)\n",
    "X_test[0] = x_test\n",
    "res = model.predict_classes(X_test)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "axes = plt.gca()\n",
    "x_min = hist.epoch[0]\n",
    "x_max = hist.epoch[-1]+1\n",
    "axes.set_xlim([x_min,x_max])\n",
    "\n",
    "plt.scatter(hist.epoch, hist.history['loss'], color='g')\n",
    "plt.plot(hist.history['loss'], color='g', label='Training Loss')\n",
    "plt.scatter(hist.epoch, hist.history['val_loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='b', label='Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss & Validation Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "axes = plt.gca()\n",
    "x_min = hist.epoch[0]\n",
    "x_max = hist.epoch[-1]+1\n",
    "axes.set_xlim([x_min,x_max])\n",
    "\n",
    "plt.scatter(hist.epoch, hist.history['acc'], color='r')\n",
    "plt.plot(hist.history['acc'], color='r', label='Training Accuracy')\n",
    "plt.scatter(hist.epoch, hist.history['val_acc'], color='c')\n",
    "plt.plot(hist.history['val_acc'], color='c', label='Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Trainging Accuracy & Validation Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
