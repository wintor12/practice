{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from __future__ import print_function\n",
    "from keras.layers.core import Activation, TimeDistributedDense, RepeatVector\n",
    "from keras.layers import recurrent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, vocab, maxlen):\n",
    "        self.vocab = vocab\n",
    "        self.maxlen = maxlen\n",
    "    \n",
    "    def encode(self, C, maxlen=None):\n",
    "        maxlen = maxlen if maxlen else self.maxlen\n",
    "        X = np.zeros((maxlen, len(self.vocab)))\n",
    "        for i, c in enumerate(C):\n",
    "            X[i, c] = 1\n",
    "        return X\n",
    "    \n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ','.join(x for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRandSeq(min, max, len):\n",
    "    return [np.random.randint(min, max) for _ in range(len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 50000\n",
    "TEST_SIZE = 10000\n",
    "DIGITS = 25\n",
    "MAXLEN = DIGITS\n",
    "voc = list(xrange(100))\n",
    "ctable = CharacterTable(voc, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "[42, 15, 82, 74, 60, 63, 16, 98, 10, 72, 62, 41, 14, 88, 91, 39, 28, 70, 98, 37, 14, 61, 60, 41, 57]\n",
      "[10, 14, 14, 15, 16, 28, 37, 39, 41, 41, 42, 57, 60, 60, 61, 62, 63, 70, 72, 74, 82, 88, 91, 98, 98]\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "inputs_t = []\n",
    "outputs_t = []\n",
    "print('Generating data...')\n",
    "while len(inputs) < TRAINING_SIZE:\n",
    "    s = generateRandSeq(0, len(voc), DIGITS)\n",
    "    inputs.append(s)\n",
    "    # outputs.append(s[::-1])\n",
    "    outputs.append(sorted(s))\n",
    "\n",
    "while len(inputs_t) < TEST_SIZE:\n",
    "    s = generateRandSeq(0, len(voc), DIGITS)\n",
    "    inputs_t.append(s)\n",
    "    # outputs_t.append(s[::-1])\n",
    "    outputs_t.append(sorted(s))\n",
    "print(inputs[12])\n",
    "print(outputs[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(inputs), MAXLEN, len(voc)), dtype=np.bool)\n",
    "y = np.zeros((len(outputs), MAXLEN, len(voc)), dtype=np.bool)\n",
    "for i, sentence in enumerate(inputs):\n",
    "    X[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "\n",
    "for i, sentence in enumerate(outputs):\n",
    "    y[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "\n",
    "X_test = np.zeros((len(inputs_t), MAXLEN, len(voc)), dtype=np.bool)\n",
    "y_test = np.zeros((len(outputs_t), MAXLEN, len(voc)), dtype=np.bool)\n",
    "for i, sentence in enumerate(inputs_t):\n",
    "    X_test[i] = ctable.encode(sentence, maxlen=MAXLEN)\n",
    "\n",
    "for i, sentence in enumerate(outputs_t):\n",
    "    y_test[i] = ctable.encode(sentence, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 25, 100)\n",
      "(50000, 25, 100)\n",
      "(10000, 25, 100)\n",
      "(10000, 25, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256\n",
    "BATCH_SIZE = 200\n",
    "LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(MAXLEN, len(voc)), return_sequences=True))\n",
    "for _ in range(LAYERS - 2):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(HIDDEN_SIZE))\n",
    "model.add(RepeatVector(MAXLEN))\n",
    "for _ in range(LAYERS):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributedDense(len(voc)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "39500/45000 [=========================>....] - ETA: 15s - loss: 1.9837 - acc: 0.2402"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, batch_size=BATCH_SIZE, nb_epoch=5,\n",
    "          show_accuracy=True,validation_split = 0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s     \n",
      "Test score: 0.000568637109245\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, batch_size=BATCH_SIZE, nb_epoch=17, callbacks=[early_stopping],\n",
    "          validation_split = 0.1, shuffle=True)\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            show_accuracy=True)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, 7, 6, 5, 4, 3, 2, 1, 0, 0, 8, 7, 7, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '12345678901234567898'\n",
    "x_test = ctable.encode(test, maxlen=MAXLEN)\n",
    "X_test = np.zeros((1, MAXLEN, len(chars)), dtype=np.bool)\n",
    "X_test[0] = x_test\n",
    "res = model.predict_classes(X_test)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "axes = plt.gca()\n",
    "x_min = hist.epoch[0]\n",
    "x_max = hist.epoch[-1]+1\n",
    "axes.set_xlim([x_min,x_max])\n",
    "\n",
    "plt.scatter(hist.epoch, hist.history['loss'], color='g')\n",
    "plt.plot(hist.history['loss'], color='g', label='Training Loss')\n",
    "plt.scatter(hist.epoch, hist.history['val_loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='b', label='Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss & Validation Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "axes = plt.gca()\n",
    "x_min = hist.epoch[0]\n",
    "x_max = hist.epoch[-1]+1\n",
    "axes.set_xlim([x_min,x_max])\n",
    "\n",
    "plt.scatter(hist.epoch, hist.history['acc'], color='r')\n",
    "plt.plot(hist.history['acc'], color='r', label='Training Accuracy')\n",
    "plt.scatter(hist.epoch, hist.history['val_acc'], color='c')\n",
    "plt.plot(hist.history['val_acc'], color='c', label='Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Trainging Accuracy & Validation Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
